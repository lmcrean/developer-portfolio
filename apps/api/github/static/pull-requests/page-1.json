{
  "data": [
    {
      "id": 2793359837,
      "number": 88,
      "title": "Fix inconsistent subscription status after cancellation with centralized cancellation logic",
      "description": "## Issue #78 \r\nAfter cancelling a subscription, the status is inconsistent across different areas (#78):\r\n- Backend Orders: shows \"pending subscription\" ❌\r\n- My Account > Subscriptions: shows \"pending subscription\" ❌  \r\n- My Account > Orders: shows \"cancelled\" ✅\r\n\r\n## Root Cause\r\nSubscription cancellation events weren't properly synchronized between orders, subscriptions, and renewal orders. The gateway was missing status propagation logic.\r\n\r\n## Solution\r\nAdd centralized cancellation handling and status synchronization:\r\n\r\n1. **Unified cancellation handler** - Single method to handle all cancellation scenarios (payment cancelled, billing request cancelled, subscription cancelled)\r\n\r\n2. **Status synchronization hooks** - Ensure parent orders reflect subscription status changes and vice versa\r\n\r\n3. **Metadata cleanup** - Clear pending payment flags when cancellation occurs\r\n\r\n## Changes\r\n- `class-wc-gocardless-gateway.php`: Add `handle_subscription_cancellation()` method\r\n- `class-wc-gocardless-gateway-addons.php`: Add `sync_parent_order_status()` hook\r\n- Update webhook handlers to use centralized cancellation logic\r\n\r\n## Testing\r\n1. Create subscription order\r\n2. Cancel subscription from frontend/backend\r\n3. Verify all areas show \"cancelled\" status consistently\r\n\r\n## Unit Test Instructions\r\n\r\n```bash\r\n# Install dependencies\r\ncomposer install\r\n\r\n# Run cancellation tests\r\nvendor/bin/phpunit --testdox --filter=\"Test_Cancellation_Simplified|Test_Parent_Order_Sync\"\r\n```\r\n\r\n**Expected:** 13/13 tests pass validating subscription cancellation logic",
      "created_at": "2025-09-02T16:50:26Z",
      "merged_at": null,
      "html_url": "https://github.com/gocardless/woocommerce-gateway-gocardless/pull/88",
      "state": "open",
      "additions": 89,
      "deletions": 5,
      "comments": 1,
      "repository": {
        "name": "woocommerce-gateway",
        "description": "A GoCardless payments integration for WooCommerce",
        "language": "PHP",
        "html_url": "https://github.com/gocardless/woocommerce-gateway-gocardless",
        "owner": {
          "login": "gocardless",
          "avatar_url": "https://avatars.githubusercontent.com/u/790629?v=4"
        }
      }
    },
    {
      "id": 2790279129,
      "number": 16,
      "title": "Fix NumberFormatException vulnerability in Content-Length header parsing",
      "description": "#15  Malformed `Content-Length` headers cause unhandled `NumberFormatException`, crashing the WebSocket handler thread and enabling trivial DoS attacks. A DoS vulnerability that can crash these connections with a single malformed header is definitely worth fixing.\r\n\r\n**Attack vector:** `curl -H \"Content-Length: not-a-number\" http://target/api`\r\n\r\n## Solution\r\nAdded try-catch blocks around `Long.parseLong()` calls in:\r\n- `CrankerRequestParser.java:61`\r\n- `ConnectorSocketV3.java:701`\r\n\r\nInvalid values now return `-1` and log warnings instead of throwing exceptions.\r\n\r\n## Impact\r\n\r\n### Before (Vulnerable)\r\n- `Long.parseLong(\"abc\")` throws uncaught `NumberFormatException`\r\n → Thread crashes, WebSocket connection drops, request fails\r\n → Single malformed request can disrupt service\r\n → Recovery Depends on thread pool size; \r\n → if repeated attacks exhaust pool → full outage\r\n\r\n### After (Fixed)  \r\n- Invalid Content-Length returns `-1` (same as missing header)\r\n → Request processed normally, treated as having unknown body length\r\n → Malformed headers handled gracefully, no service impact\r\n → Recovery: Not needed; service remains fully operational\r\n\r\n\r\n\r\n## Testing Guide\r\n```bash\r\n# Test malformed values (should return HTTP error, not crash)\r\ncurl -H \"Content-Length: abc\" http://localhost:8080/api\r\ncurl -H \"Content-Length: 12.5\" http://localhost:8080/api\r\ncurl -H \"Content-Length: \" http://localhost:8080/api\r\n\r\n# Verify service still running\r\ncurl -I http://localhost:8080/health\r\n```\r\n\r\n## Breaking Changes\r\nNone. Invalid Content-Length headers already violated HTTP spec - this change makes handling RFC-compliant by treating malformed values as missing headers.\r\n\r\n### Why This Is Not \"False Passing\":\r\n- **-1 means \"unknown length\"**, not \"no body\" - per Java HttpClient spec\r\n- **Body still transmitted:** Actual content flows through WebSocket binary messages regardless of Content-Length\r\n- **Request validation continues:** Other security checks and validations still apply",
      "created_at": "2025-09-01T16:06:23Z",
      "merged_at": null,
      "html_url": "https://github.com/hsbc/cranker-connector/pull/16",
      "state": "open",
      "additions": 18,
      "deletions": 2,
      "comments": 0,
      "repository": {
        "name": "cranker-connector",
        "description": "A Cranker connector for Java as a library that has no external dependencies.",
        "language": "Java",
        "html_url": "https://github.com/hsbc/cranker-connector",
        "owner": {
          "login": "hsbc",
          "avatar_url": "https://avatars.githubusercontent.com/u/48318517?v=4"
        }
      }
    },
    {
      "id": 2787729818,
      "number": 9,
      "title": "Enhance(error handling): improve flush loop and trigger handling in cscdm",
      "description": "\r\n## Problem Statement\r\nThe flush loop creates a new goroutine on every iteration that blocks on `sync.Cond.Wait()`. When `return` is removed to fix error resilience, this causes a goroutine leak as abandoned goroutines accumulate. See #8.\r\n\r\nInspecting `internal\\cscdm\\cscdm.go`:\r\n1. **Error kills loop**: `return` on error terminates goroutine permanently\r\n2. **Goroutine leak**: Each iteration creates new goroutine that blocks on `Wait()`\r\n3. **Tooling**: `sync.Cond` with select requires a goroutine-bridge pattern that causes the leak\r\n\r\n##  Solution\r\n1. **Replace sync.Cond with buffered channel**: Simpler, cleaner concurrency\r\n2. **Remove goroutine creation in loop**: No more leaks\r\n3. **Remove `return` on error**: Allows recovery from transient failures\r\n4. **Add `sync.Once` to Stop()**: Prevents panic from multiple closes\r\n\r\n## Impact\r\n\r\n**Before**: Any error leads to permanent death, silent failures\r\n**After**: Errors logged, processing continues, transient failures recover\r\n\r\n## Testing\r\n- [x] Build successful - `terraform-provider-cscdm.exe`\r\n  created\r\n- [x] Static analysis passed - go vet found no issues.\r\n- [x] Unit and integration tests added as sibling files in line with go conventions\r\n\r\n### How to test\r\nModerators can confirm the fix has 100% pass rate with `make testacc` or `make test` cmd\r\n\r\n## Breaking changes\r\nnone - API functions unchanged, the provider still works exactly the same in success scenarios, it just becomes more resilient in realistic error scenarios.",
      "created_at": "2025-08-31T13:37:08Z",
      "merged_at": null,
      "html_url": "https://github.com/rropen/terraform-provider-cscdm/pull/9",
      "state": "open",
      "additions": 483,
      "deletions": 19,
      "comments": 2,
      "repository": {
        "name": "terraform-provider-c",
        "description": "Terraform Provider for CSC Domain Manager.",
        "language": "Go",
        "html_url": "https://github.com/rropen/terraform-provider-cscdm",
        "owner": {
          "login": "rropen",
          "avatar_url": "https://avatars.githubusercontent.com/u/86787483?v=4"
        }
      }
    },
    {
      "id": 2786918386,
      "number": 17,
      "title": "Add Code Coverage Infrastructure",
      "description": "Adds code coverage reporting infrastructure to docorator using covr and Codecov integration. This establishes the foundation for tracking test coverage metrics without modifying any package functionality.\r\n\r\n## Changes\r\n- **DESCRIPTION**: Added `covr` to Suggests\r\n- **README.md**: Added Codecov badge \r\n- **.github/workflows/test-coverage.yml**: New GitHub Actions workflow for coverage reporting\r\n\r\n## Testing for Reviewers\r\n```r\r\n# Install package with suggests\r\ndevtools::install(dependencies = TRUE)\r\n\r\n# Verify covr can be loaded\r\nlibrary(covr)\r\n\r\n# Run coverage (will work locally)\r\npackage_coverage()\r\n```\r\n\r\n## Prerequisites for Full Functionality\r\n**Repository admin must enable Codecov:**\r\n1. Visit https://github.com/apps/codecov\r\n2. Grant access to GSK-Biostatistics/docorator\r\n\r\nWithout this, the workflow will run but fail at the upload step (expected).\r\n\r\n## Notes\r\n- Workflow triggers on PRs and pushes to main/master\r\n- Uses standard r-lib/actions templates\r\n- No breaking changes -- safe to implement\r\n- Coverage percentages will be available after Codecov activation\r\n\r\naddresses #16 ",
      "created_at": "2025-08-30T16:26:40Z",
      "merged_at": null,
      "html_url": "https://github.com/GSK-Biostatistics/docorator/pull/17",
      "state": "open",
      "additions": 55,
      "deletions": 1,
      "comments": 0,
      "repository": {
        "name": "docorator",
        "description": null,
        "language": "R",
        "html_url": "https://github.com/GSK-Biostatistics/docorator",
        "owner": {
          "login": "GSK-Biostatistics",
          "avatar_url": "https://avatars.githubusercontent.com/u/87132606?v=4"
        }
      }
    },
    {
      "id": 2760288725,
      "number": 5595,
      "title": "Disable LDL/STL checks for CTK < 13.1 (nvbug 5243118)",
      "description": "## Problem statement\r\n\r\nIssue #5560: c.parallel tests incorrectly perform SASS validation for LDL/STL instructions on CTK < 13.1, causing false positives due to nvbug 5243118 where nvrtc generates these instructions when nvcc would not.\r\n\r\n## Solution\r\n\r\nSince c.parallel **always** uses nvrtc internally for kernel compilation (not nvcc), the fix unconditionally applies CTK version checks:\r\n\r\n### C++ Changes\r\n- Added `is_ctk_version_allows_sass_check()` helper function in `test_util.h` that checks CTK version using `__CUDACC_VER_MAJOR__` and `__CUDACC_VER_MINOR__` macros\r\n- Returns `true` for CTK ≥ 13.1 (where bug is fixed), `false` otherwise\r\n- Updated `should_check_sass()` in `test_scan.cpp` and `test_unique_by_key.cpp` to use this helper\r\n\r\n### Python Changes  \r\n- Added `_should_check_sass_for_ctk_version()` in `_cccl_interop.py` that checks runtime CTK version\r\n- Modified `call_build()` to only perform SASS checks when both `_check_sass` is enabled AND CTK ≥ 13.1\r\n- Updated `conftest.py` fixture to emit warning when SASS checks are disabled due to CTK version\r\n- Simplified `test_scan.py` to remove CC 9.0+ check (now handled by CTK version check)\r\n\r\n## Testing guide\r\n\r\n**Expected behavior:**\r\n- CTK < 13.1: SASS validation disabled (with warning), tests pass without false positives\r\n- CTK ≥ 13.1: SASS validation enabled, properly catches real LDL/STL issues\r\n- Complex types still skip SASS checks via existing logic\r\n\r\n## Breaking Changes\r\n\r\n**None** - This is a backward-compatible fix that only affects internal test validation logic. No changes to public APIs, library functionality, build system, or dependencies.\r\n\r\n## Checklist\r\n- [x] I am familiar with the [Contributing Guidelines]().\r\n- [x] New or existing tests cover these changes.\r\n- [x] The documentation is up to date with these changes.\r\n",
      "created_at": "2025-08-20T15:58:10Z",
      "merged_at": null,
      "html_url": "https://github.com/NVIDIA/cccl/pull/5595",
      "state": "open",
      "additions": 122,
      "deletions": 16,
      "comments": 7,
      "repository": {
        "name": "cccl",
        "description": "CUDA Core Compute Libraries",
        "language": "C++",
        "html_url": "https://github.com/NVIDIA/cccl",
        "owner": {
          "login": "NVIDIA",
          "avatar_url": "https://avatars.githubusercontent.com/u/1728152?v=4"
        }
      }
    },
    {
      "id": 2759515533,
      "number": 1478,
      "title": "Return undefined instead of invalid action names for partial matches ",
      "description": "Partially fixes #1474 - Prevents exception when typing partial cached commands by properly handling undefined action names.\r\n\r\n### Problem\r\nCache contains \"open bbc webpage\" → \"browser.openWebPage\". Typing just \"open\" throws exception because:\r\n1. `constructionValue.ts` returns `{ fullActionName: \"unknown.unknown\" }` \r\n2. `fromJsonAction` tries to parse \"unknown.unknown\" and fails\r\n\r\n### Solution\r\nTwo coordinated changes to handle partial matches gracefully:\r\n\r\n**1. constructionValue.ts**: Return `undefined` instead of \"unknown.unknown\" for partial matches\r\n```diff\r\n- return { fullActionName: \"unknown.unknown\" };\r\n+ return { fullActionName: undefined }; // Return undefined for partial matches\r\n```\r\n\r\n**2. requestAction.ts**: Handle undefined `fullActionName` in `fromJsonAction`\r\n```typescript\r\nconst { schemaName, actionName } =\r\n    actionJSON.fullActionName !== undefined\r\n        ? parseFullActionNameParts(actionJSON.fullActionName)\r\n        : { schemaName: undefined as any, actionName: undefined as any };\r\n```\r\n\r\n### Testing\r\n1. Execute: `open bbc webpage` (populates cache)  \r\n2. Type: `open` (partial match triggers completion)\r\n3. **Before**: Throws exception attempting to parse \"unknown.unknown\"\r\n4. **After**: No exception - returns undefined gracefully, preventing crash",
      "created_at": "2025-08-20T11:47:09Z",
      "merged_at": "2025-08-21T22:32:05Z",
      "html_url": "https://github.com/microsoft/TypeAgent/pull/1478",
      "state": "merged",
      "additions": 10,
      "deletions": 10,
      "comments": 5,
      "repository": {
        "name": "TypeAgent",
        "description": "Sample code that explores an architecture for using language models to build a personal agent that can work with application agents.",
        "language": "TypeScript",
        "html_url": "https://github.com/microsoft/TypeAgent",
        "owner": {
          "login": "microsoft",
          "avatar_url": "https://avatars.githubusercontent.com/u/6154722?v=4"
        }
      }
    },
    {
      "id": 2746051142,
      "number": 232,
      "title": "Fix: Support `GENERATED ALWAYS AS` columns to reduce migration failures (#212)",
      "description": "## Problem Statement (#212)\r\n\r\npg-schema-diff incorrectly treats `GENERATED ALWAYS AS (expression) STORED` columns as `DEFAULT` columns, causing migration failures:\r\n\r\n```\r\nERROR: cannot use column reference in DEFAULT expression (SQLSTATE 0A000)\r\n```\r\n\r\n**Example**: A `tsvector` column with `GENERATED ALWAYS AS (to_tsvector('simple', title || ' ' || coalesce(artist, ''))) STORED` gets incorrectly converted to `DEFAULT to_tsvector(...)`, which fails because DEFAULT expressions cannot reference other columns.\r\n\r\n## Root Cause Analysis\r\n\r\n1. **Schema Introspection** (`internal/queries/queries.sql:91-151`): \r\n   - The `GetColumnsForTable` query doesn't check `pg_attribute.attgenerated` \r\n   - It treats all columns with expressions as DEFAULT columns\r\n\r\n2. **DDL Generation** (`pkg/diff/sql_generator.go:2671`):\r\n   - The `buildColumnDefinition` function only handles DEFAULT expressions\r\n   - No support for `GENERATED ALWAYS AS ... STORED` syntax\r\n\r\n## Solution\r\n\r\n### 1. Update Schema Introspection ✅\r\n**Modified** `internal/queries/queries.sql:94-106`:\r\n- Added `pg_attribute.attgenerated` detection ('s' = STORED generated column)\r\n- Split default and generation expressions using CASE statements:\r\n  ```sql\r\n  -- Only populate default_value for non-generated columns\r\n  COALESCE(\r\n      CASE \r\n          WHEN a.attgenerated = 's' THEN ''\r\n          ELSE pg_catalog.pg_get_expr(d.adbin, d.adrelid)\r\n      END, ''\r\n  )::TEXT AS default_value,\r\n  -- Only populate generation_expression for generated columns\r\n  COALESCE(\r\n      CASE\r\n          WHEN a.attgenerated = 's' THEN pg_catalog.pg_get_expr(d.adbin, d.adrelid)\r\n          ELSE ''\r\n      END, ''\r\n  )::TEXT AS generation_expression,\r\n  (a.attgenerated = 's') AS is_generated,\r\n  ```\r\n\r\n**Updated** `internal/queries/queries.sql.go` with new struct fields:\r\n- Added `GenerationExpression string`\r\n- Added `IsGenerated bool`\r\n- Updated row scanning to handle new fields\r\n\r\n### 2. Extend Column Model ✅\r\n**Enhanced** `internal/schema/schema.go:268-275`:\r\n```go\r\nColumn struct {\r\n    Name      string\r\n    Type      string\r\n    Collation SchemaQualifiedName\r\n    Default   string\r\n    // NEW: Generated column support\r\n    IsGenerated          bool\r\n    GenerationExpression string\r\n    IsNullable bool\r\n    Size     int\r\n    Identity *ColumnIdentity\r\n}\r\n```\r\n\r\n**Updated** `internal/schema/schema.go:992-996` column building logic:\r\n```go\r\ncolumns = append(columns, Column{\r\n    // ... existing fields ...\r\n    Default:             column.DefaultValue,\r\n    IsGenerated:         column.IsGenerated,\r\n    GenerationExpression: column.GenerationExpression,\r\n    // ... rest of fields ...\r\n})\r\n```\r\n\r\n### 3. Fix DDL Generation ✅\r\n**Fixed** `pkg/diff/sql_generator.go:2677-2681`:\r\n```go\r\nfunc buildColumnDefinition(column schema.Column) (string, error) {\r\n    sb := strings.Builder{}\r\n    sb.WriteString(fmt.Sprintf(\"%s %s\", schema.EscapeIdentifier(column.Name), column.Type))\r\n    if column.IsCollated() {\r\n        sb.WriteString(fmt.Sprintf(\" COLLATE %s\", column.Collation.GetFQEscapedName()))\r\n    }\r\n    // NEW: Handle generated columns first\r\n    if column.IsGenerated {\r\n        sb.WriteString(fmt.Sprintf(\" GENERATED ALWAYS AS (%s) STORED\", column.GenerationExpression))\r\n    } else if len(column.Default) > 0 {\r\n        sb.WriteString(fmt.Sprintf(\" DEFAULT %s\", column.Default))\r\n    }\r\n    if !column.IsNullable {\r\n        sb.WriteString(\" NOT NULL\")\r\n    }\r\n    // ... identity handling ...\r\n    return sb.String(), nil\r\n}\r\n```\r\n\r\n## Test Plan for Reviewers\r\n\r\n### 1. Automated Test Validation (Required)\r\n\r\nRun the automated test suite to verify all generated column functionality:\r\n\r\n```bash\r\n# Test generated column functionality (~6 seconds)\r\nPATH=\"/usr/lib/postgresql/16/bin:$PATH\" go test ./internal/migration_acceptance_tests -run \"TestColumnTestCases/.*[Gg]enerated.*\" -v\r\n\r\n# Test DDL generation unit tests (instant, no PostgreSQL needed)\r\ngo test ./pkg/diff -run \"TestBuildColumnDefinition\" -v\r\n\r\n# Verify no regressions in unit tests (instant)\r\ngo test ./pkg/diff -run \"TestBuild|TestTransform|TestPlan\"\r\n```\r\n\r\n**Success Criteria:**\r\n- All 5 generated column integration tests pass\r\n- All 4 column definition unit tests pass  \r\n- No unit test failures\r\n\r\n### 2. Manual End-to-End Validation (Optional)\r\n\r\nTo manually verify the fix resolves the original issue:\r\n\r\n<details><summary>Manual Test Steps</summary>\r\n\r\n```bash\r\n# 1. Start test database\r\ndocker run -d --name pg-test-generated \\\r\n  -e POSTGRES_PASSWORD=postgres \\\r\n  -e POSTGRES_DB=testdb \\\r\n  -p 5433:5432 postgres:15\r\n\r\n# 2. Create initial table\r\ndocker exec pg-test-generated psql -U postgres -d testdb -c \"\r\nCREATE TABLE public.tabs (\r\n    id serial PRIMARY KEY,\r\n    title text NOT NULL,\r\n    artist text\r\n);\"\r\n\r\n# 3. Create target schema with generated column\r\nmkdir test_schema_generated\r\ncat > test_schema_generated/tabs.sql << 'EOF'\r\nCREATE TABLE public.tabs (\r\n    id serial PRIMARY KEY,\r\n    title text NOT NULL,\r\n    artist text,\r\n    search_vector tsvector GENERATED ALWAYS AS (\r\n        to_tsvector('simple', title || ' ' || coalesce(artist, ''))\r\n    ) STORED\r\n);\r\nEOF\r\n\r\n# 4. Build and test pg-schema-diff  \r\ngo build -o pg-schema-diff ./cmd/pg-schema-diff\r\n\r\n# 5. Generate and apply migration (should succeed without errors)\r\n./pg-schema-diff apply \\\r\n  --from-dsn \"postgres://postgres:postgres@localhost:5433/testdb?sslmode=disable\" \\\r\n  --to-dir test_schema_generated\r\n\r\n# 6. Verify generated column works\r\ndocker exec pg-test-generated psql -U postgres -d testdb -c \"\r\nINSERT INTO public.tabs (title, artist) VALUES ('Hello World', 'Test Artist');\r\nSELECT title, artist, search_vector FROM public.tabs;\r\n\"\r\n\r\n# 7. Cleanup\r\ndocker stop pg-test-generated && docker rm pg-test-generated\r\nrm -rf test_schema_generated\r\n```\r\n\r\n**Expected Behavior:**\r\n- Migration applies successfully (no SQLSTATE 0A000 error)\r\n- Generated column automatically populates with tsvector data\r\n- DDL contains `GENERATED ALWAYS AS ... STORED` (not `DEFAULT`)\r\n\r\n</details>\r\n\r\n### 3. Regression Testing (Required)\r\n\r\nVerify existing functionality remains intact:\r\n\r\n```bash\r\n# Build verification (instant)\r\ngo build ./... && go vet ./...\r\n\r\n# Unit test verification (instant, no PostgreSQL needed)\r\ngo test ./pkg/diff -run \"TestBuild|TestTransform|TestPlan\"\r\n```\r\n\r\n**Full Regression Testing (Recommended):**\r\n```bash\r\n# Run complete test suite in Docker environment (as documented in CONTRIBUTING.md)\r\ndocker build -t pg-schema-diff-test-runner -f ./build/Dockerfile.test --build-arg POSTGRES_PACKAGE=postgresql16 .\r\ndocker run pg-schema-diff-test-runner\r\n```\r\n\r\n**Note**: Docker-based testing provides consistent environment and runs all integration tests including schema hash validations. This is the same test suite used in CI.\r\n\r\n## Impact\r\n\r\nThis fix properly supports PostgreSQL's generated columns feature (PostgreSQL 12+), commonly used for:\r\n- ✅ Full-text search vectors (`tsvector` columns)\r\n- ✅ Computed/derived columns (`price * tax_rate`)\r\n- ✅ JSON field extraction (`(data->>'field')::type`)\r\n- ✅ Automatic transformations (`upper(name)`, `lower(email)`)\r\n\r\n**Docs:**\r\nhttps://www.postgresql.org/docs/current/ddl-generated-columns.html",
      "created_at": "2025-08-14T12:36:59Z",
      "merged_at": "2025-08-27T20:12:01Z",
      "html_url": "https://github.com/stripe/pg-schema-diff/pull/232",
      "state": "merged",
      "additions": 275,
      "deletions": 37,
      "comments": 11,
      "repository": {
        "name": "pg-schema-diff",
        "description": "Go library for diffing Postgres schemas and generating SQL migrations",
        "language": "Go",
        "html_url": "https://github.com/stripe/pg-schema-diff",
        "owner": {
          "login": "stripe",
          "avatar_url": "https://avatars.githubusercontent.com/u/856813?v=4"
        }
      }
    },
    {
      "id": 2728241517,
      "number": 12806,
      "title": "utils: use `ShardIdentity` in `postgres_client.rs` for improved type safety",
      "description": "## Summary\r\n\r\nThis PR refactors `postgres_client.rs` to use the existing `ShardIdentity` type instead of individual primitive shard fields, improving type safety and reducing code duplication.\r\n\r\n**Fixes #9823**\r\n\r\n## Problem\r\n\r\nThe `ConnectionConfigArgs` struct in `utils/postgres_client.rs` was manually tracking shard information using individual primitive fields:\r\n\r\n```rust\r\npub struct ConnectionConfigArgs<'a> {\r\n    pub shard_number: Option<u8>,        // ❌ Primitive types\r\n    pub shard_count: Option<u8>,         // ❌ No type safety\r\n    pub shard_stripe_size: Option<u32>,  // ❌ Manual validation \r\n    // ...\r\n}\r\n```\r\n\r\nThis approach had several issues:\r\n- **Type Safety**: Primitive types allowed mixing up parameters (e.g., passing shard_count where shard_number expected)\r\n- **Manual Validation**: Required runtime assertions to ensure all three fields were consistent\r\n- **Code Duplication**: Reinvented shard representation instead of using existing `ShardIdentity` type\r\n- **API Complexity**: Three separate `Option<T>` fields instead of one cohesive parameter\r\n\r\n## Solution\r\n\r\n### Phase 1: Move `ShardIdentity` to `utils`\r\n\r\n- [x] Moved `ShardIdentity` struct from `pageserver_api/shard.rs` to `utils/shard.rs`\r\n- [x] Moved related types: `ShardLayout`, `ShardConfigError`, `DEFAULT_STRIPE_SIZE`\r\n- [x] Updated `pageserver_api` to re-export from `utils` for backward compatibility\r\n- [x] Preserved pageserver-specific extension methods in `pageserver_api`\r\n\r\n### Phase 2: Refactor `ConnectionConfigArgs`\r\n\r\n- [x] Replace three individual fields with single `shard: Option<ShardIdentity>` field\r\n- [x] Update `options()` method to extract values from `ShardIdentity`\r\n- [x] Update all callers to use the unified type\r\n\r\n## Changes Made\r\n\r\n### Core Infrastructure\r\n- **`libs/utils/src/shard.rs`**: Added `ShardIdentity` struct with all core methods\r\n- **`libs/pageserver_api/src/shard.rs`**: Now re-exports from utils with pageserver-specific extensions  \r\n- **`libs/utils/src/postgres_client.rs`**: Refactored to use `Option<ShardIdentity>`\r\n\r\n### Updated Files\r\n- **`safekeeper/src/recovery.rs`**: Updated `ConnectionConfigArgs` constructor\r\n- **`pageserver/src/tenant/timeline/walreceiver/connection_manager.rs`**: Updated constructor\r\n\r\n## Benefits\r\n\r\n### **Type Safety**\r\n```rust\r\n// Before: Runtime assertions and unsafe unwraps\r\nif self.shard_number.is_some() {\r\n    assert!(self.shard_count.is_some());      // Runtime check\r\n    options.push(format!(\"shard_count={}\", self.shard_count.unwrap())); // Panic risk\r\n}\r\n\r\n// After: Compile-time guarantees\r\nif let Some(shard) = &self.shard {\r\n    options.push(format!(\"shard_count={}\", shard.count.literal())); // Type safe\r\n}\r\n```\r\n\r\n### **Simplified API**\r\n```rust\r\n// Before: 3 separate parameters\r\nConnectionConfigArgs {\r\n    shard_number: Some(0),\r\n    shard_count: Some(4), \r\n    shard_stripe_size: Some(2048),\r\n    // ...\r\n}\r\n\r\n// After: 1 unified parameter\r\nConnectionConfigArgs {\r\n    shard: Some(ShardIdentity::new(\r\n        ShardNumber(0), \r\n        ShardCount(4), \r\n        ShardStripeSize(2048)\r\n    ).unwrap()),\r\n    // ...\r\n}\r\n```\r\n\r\n### **Code Consistency**\r\n- Now uses the same `ShardIdentity` type as the rest of the codebase\r\n- Leverages existing validation and utility methods\r\n- Eliminates duplicate shard representation\r\n\r\n## Testing\r\n\r\n- [x] Added 6 comprehensive unit tests to verify identical option string generation\r\n- [x] Integration tests confirm WAL streaming functionality unchanged  \r\n- [x] All affected crates build successfully\r\n- [x] Existing test suite passes without modification\r\n- [x] Manual testing with local sharded tenants\r\n\r\n## Performance Impact\r\n\r\nNone - this is a purely structural refactoring with no runtime performance implications. The generated connection options remain identical.\r\n\r\n## Migration Guide\r\n\r\nFor code outside this repository using `ConnectionConfigArgs`:\r\n\r\n```rust\r\n// Before\r\nConnectionConfigArgs {\r\n    shard_number: Some(0),\r\n    shard_count: Some(4),\r\n    shard_stripe_size: Some(2048),\r\n    // ... other fields\r\n}\r\n\r\n// After  \r\nConnectionConfigArgs {\r\n    shard: Some(ShardIdentity::new(\r\n        ShardNumber(0),\r\n        ShardCount::new(4), \r\n        ShardStripeSize(2048)\r\n    ).unwrap()),\r\n    // ... other fields\r\n}\r\n```\r\n\r\nOr for unsharded connections:\r\n```rust\r\nConnectionConfigArgs {\r\n    shard: None,  // Replaces three None fields\r\n    // ... other fields\r\n}\r\n```\r\n\r\n## Backward Compatibility\r\n\r\n- [x] All existing imports of `ShardIdentity` continue to work via re-exports\r\n- [x] No breaking changes to public APIs outside of `ConnectionConfigArgs`\r\n- [x] Migration was designed to be incremental and reversible\r\n\r\n## Related\r\n\r\n- **Original Discussion**: https://github.com/neondatabase/neon/pull/9746#discussion_r1846338796\r\n- **Architecture Decision**: Move `ShardIdentity` to `utils` to avoid circular dependencies #9823 \r\n\r\n## Review Notes\r\n\r\nThis refactoring demonstrates several Rust best practices:\r\n1. **\"Make invalid states unrepresentable\"** - Use the type system to prevent bugs\r\n2. **DRY principle** - Reuse existing well-designed types instead of duplicating concepts  \r\n3. **Type safety over runtime checks** - Catch errors at compile time, not runtime\r\n4. **Proper encapsulation** - Group related data together in meaningful abstractions\r\n\r\nThe changes are purely structural with no behavioral modifications, making this a safe refactoring that improves code quality without affecting functionality.",
      "created_at": "2025-08-07T15:42:07Z",
      "merged_at": null,
      "html_url": "https://github.com/neondatabase/neon/pull/12806",
      "state": "open",
      "additions": 390,
      "deletions": 164,
      "comments": 3,
      "repository": {
        "name": "neon",
        "description": "Neon: Serverless Postgres. We separated storage and compute to offer autoscaling, code-like database branching, and scale to zero.",
        "language": "Rust",
        "html_url": "https://github.com/neondatabase/neon",
        "owner": {
          "login": "neondatabase",
          "avatar_url": "https://avatars.githubusercontent.com/u/77690634?v=4"
        }
      }
    },
    {
      "id": 2696869536,
      "number": 6982,
      "title": "Enhance (version control): Add milestone lock feature to prevent accidental deletion and bad actor interventions",
      "description": "# Screenshots\r\n\r\n<img width=\"175\" height=\"auto\" alt=\"image\" src=\"https://github.com/user-attachments/assets/0b2800e3-4643-42d8-a235-3cf4c03333f0\" /><img width=\"175\" height=\"auto\" alt=\"image\" src=\"https://github.com/user-attachments/assets/0d465303-17c0-44cd-b867-53a86d698d44\" /><img width=\"175\" height=\"auto\" alt=\"image\" src=\"https://github.com/user-attachments/assets/7a0203aa-ee30-4e7f-a696-d5c2a6783ca7\" /><img width=\"175\" height=\"auto\" alt=\"image\" src=\"https://github.com/user-attachments/assets/83ff07d4-e5a1-45ac-9f72-feb9140aa5e3\" />\r\n<i><b>Current (problem):</b> Point of view of user LC. important milestones are able to be deleted accidentally or intentionally by other user's. LC can delete MC's work, after 7 days it is lost forever. </i>\r\n\r\n---\r\n<img width=\"175\" height=\"auto\" alt=\"image\" src=\"https://github.com/user-attachments/assets/be501f4f-462f-453e-8db5-896ce93ed9b4\" />\r\n<img width=\"175\" height=\"auto\" alt=\"final2\" src=\"https://github.com/user-attachments/assets/2268d10c-d512-4ef2-a29d-ef63770fb04b\" />\r\n<img width=\"175\" height=\"auto\" alt=\"image\" src=\"https://github.com/user-attachments/assets/4785c480-9f8c-4ad0-911d-49f682c74b7a\" />\r\n<img width=\"174\" height=\"auto\" alt=\"final1\" src=\"https://github.com/user-attachments/assets/bbdd8cd5-4033-4e02-9c24-5f071a3a0aed\" /><br>\r\n<i><b>Enhancement (new):</b> Point of view of user UB. Important milestones are now protected with a simple lock feature. UB cannot delete (or rename) LC's work when it is locked. </i>\r\n\r\n---\r\n\r\nThis PR implements a comprehensive version locking system that allows users to \"lock\" their saved versions to prevent deletion by other team members. The enhancement was requested on #6763. \r\n\r\n## Problem statement\r\n\r\n- The need for good Version Control has been an significant theme in the penpot community -- see https://community.penpot.app/t/using-version-control-to-collaboratively-work-on-penpot/633/3 and https://tree.taiga.io/project/penpot/us/187?milestone=262806. Currently there has been a milestone system implemented that enables user's to save important versions of the project. This is a highly valuable feature, however there are scenarios where it can be lost:\r\n- User A has saved a crucial \"milestone\" of a project. User B accidentally deletes it when meaning to restore the version. After 7 days, no records remain of User A's milestone and it is lost forever.\r\n- User A has saved a crucial \"milestone\" of a project. User B is a bad actor and intentionally deletes the version. After 7 days, no records remain of User A's milestone and it is lost forever.\r\n- Penpot's key competitor, Figma offers a git-style \"branching\" feature as a solution to the accidental deletion/ bad actor problem on their premium paid tier -- even if this feature were copied this could not be implemented without dramatic file changes -- leaving vulnerability to unforseen bugs.\r\n\r\n## Solution\r\n- The simplest solution is best. A \"lock\" feature for milestones. Now User A's \"milestone\" can be locked and it is protected from accidental deletion and bad actors.\r\n\r\n### Key Features\r\n- ✅ Only version creators can lock/unlock their own version milestones\r\n- ✅ Only version creators can rename their own version\r\n- ✅ Locked versions cannot be deleted by anyone except the creator  \r\n- ✅ System snapshots cannot be locked (only user-created versions)\r\n- ✅ Clear visual indicators and menu options in the UI, reuse of the \"lock\" icon\r\n- ✅ Comprehensive authorization checks and error handling in the frontend and backend\r\n\r\n\r\n### Implementation Overview\r\n- **Database**: Added `locked_by` column to `file_change` table in new migration file `backend/src/app/migrations/sql/0140-add-locked-by-column-to-file-change-table.sql`\r\n- **Backend**: New RPC endpoints for lock/unlock operations with authorization in `backend/src/app/rpc/commands/files_snapshot.clj`\r\n- **Frontend**: Lock/unlock UI in version history sidebar with visual indicators gracefully handles conditional rendering of lock and rename features.\r\n\r\n## Testing Instructions\r\n\r\n### Core Functionality Tests\r\n\r\n**Version Locking**\r\n1. Create a user version (\"Save Version\")\r\n2. Lock it via menu → \"Lock\"\r\n3. Verify lock indicator appears\r\n4. Unlock via menu → \"Unlock\"\r\n5. **Expected**: Lock/unlock works, visual indicators update correctly\r\n\r\n**Delete Protection**\r\n1. Lock a version you created\r\n2. Attempt to delete it\r\n3. **Expected**: Deletion blocked with clear error message\r\n\r\n**Authorization**\r\n1. User A creates and locks a version\r\n2. User B tries to lock/unlock/delete it\r\n3. **Expected**: User B's options to rename and delete are hidden.\r\n\r\n**System Snapshots**\r\n1. Try to lock an auto-saved system snapshot\r\n2. **Expected**: Operation fails with \"system snapshots cannot be locked\" error\r\n\r\n**UI Verification**\r\n- [x] Lock/unlock options appear only for your own user versions\r\n- [x] Locked versions display lock icon consistently\r\n- [x] Menu text changes appropriately (\"Lock\" ↔ \"Unlock\")\r\n- [x] Error messages are clear and actionable (ensured backend prevents user B deleting User A locked milestone) -- frontend handles gracefully with hidden buttons, leads to gateway error pages if forced.",
      "created_at": "2025-07-26T10:41:46Z",
      "merged_at": "2025-07-26T12:15:30Z",
      "html_url": "https://github.com/penpot/penpot/commit/0b47a366abb56fe553c70ab6716230b1b4646071",
      "state": "merged",
      "additions": 292,
      "deletions": 17,
      "comments": 5,
      "repository": {
        "name": "penpot",
        "description": "Penpot: The open-source design tool for design and code collaboration",
        "language": "Clojure, SQL",
        "html_url": "https://github.com/penpot/penpot",
        "owner": {
          "login": "penpot",
          "avatar_url": "https://avatars.githubusercontent.com/u/30179644?v=4"
        }
      }
    }
  ],
  "meta": {
    "username": "lmcrean",
    "count": 10,
    "pagination": {
      "page": 1,
      "per_page": 20,
      "total_count": 10,
      "total_pages": 1,
      "has_next_page": false,
      "has_previous_page": false
    }
  }
}